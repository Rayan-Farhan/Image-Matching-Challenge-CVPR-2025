{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c658e5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T21:59:04.124027Z",
     "iopub.status.busy": "2025-12-07T21:59:04.123445Z",
     "iopub.status.idle": "2025-12-07T21:59:10.757404Z",
     "shell.execute_reply": "2025-12-07T21:59:10.756381Z"
    },
    "papermill": {
     "duration": 6.638873,
     "end_time": "2025-12-07T21:59:10.758980",
     "exception": false,
     "start_time": "2025-12-07T21:59:04.120107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/imc2025-packages-python-11-new/hdbscan-0.8.40-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Processing /kaggle/input/imc2025-packages-python-11-new/kornia-0.7.2-py2.py3-none-any.whl\r\n",
      "Processing /kaggle/input/imc2025-packages-python-11-new/kornia_moons-0.2.9-py3-none-any.whl\r\n",
      "Processing /kaggle/input/imc2025-packages-python-11-new/kornia_rs-0.1.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Processing /kaggle/input/imc2025-packages-python-11-new/lightglue-0.0-py3-none-any.whl\r\n",
      "Processing /kaggle/input/imc2025-packages-python-11-new/pycolmap-3.11.1-cp311-cp311-manylinux_2_28_x86_64.whl\r\n",
      "Processing /kaggle/input/imc2025-packages-python-11-new/rerun_sdk-0.15.0a2-cp38-abi3-manylinux_2_31_x86_64.whl\r\n",
      "Processing /kaggle/input/imc2025-packages-python-11-new/rich-13.9.0-py3-none-any.whl\r\n",
      "hdbscan is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\r\n",
      "Installing collected packages: rich, rerun-sdk, pycolmap, lightglue, kornia-rs, kornia-moons, kornia\r\n",
      "  Attempting uninstall: rich\r\n",
      "    Found existing installation: rich 14.2.0\r\n",
      "    Uninstalling rich-14.2.0:\r\n",
      "      Successfully uninstalled rich-14.2.0\r\n",
      "  Attempting uninstall: kornia-rs\r\n",
      "    Found existing installation: kornia_rs 0.1.9\r\n",
      "    Uninstalling kornia_rs-0.1.9:\r\n",
      "      Successfully uninstalled kornia_rs-0.1.9\r\n",
      "  Attempting uninstall: kornia\r\n",
      "    Found existing installation: kornia 0.8.1\r\n",
      "    Uninstalling kornia-0.8.1:\r\n",
      "      Successfully uninstalled kornia-0.8.1\r\n",
      "Successfully installed kornia-0.7.2 kornia-moons-0.2.9 kornia-rs-0.1.8 lightglue-0.0 pycolmap-3.11.1 rerun-sdk-0.15.0a2 rich-13.9.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --no-index /kaggle/input/imc2025-packages-python-11-new/* --no-deps\n",
    "!mkdir -p /root/.cache/torch/hub/checkpoints\n",
    "!cp /kaggle/input/aliked/pytorch/aliked-n16/1/aliked-n16.pth /root/.cache/torch/hub/checkpoints/\n",
    "!cp /kaggle/input/lightglue/pytorch/aliked/1/aliked_lightglue.pth /root/.cache/torch/hub/checkpoints/\n",
    "!cp /kaggle/input/lightglue/pytorch/aliked/1/aliked_lightglue.pth /root/.cache/torch/hub/checkpoints/aliked_lightglue_v0-1_arxiv-pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ad6b79d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T21:59:10.765662Z",
     "iopub.status.busy": "2025-12-07T21:59:10.765419Z",
     "iopub.status.idle": "2025-12-07T21:59:39.579358Z",
     "shell.execute_reply": "2025-12-07T21:59:39.578756Z"
    },
    "papermill": {
     "duration": 28.818796,
     "end_time": "2025-12-07T21:59:39.580756",
     "exception": false,
     "start_time": "2025-12-07T21:59:10.761960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/kornia/feature/lightglue.py:44: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)\n",
      "/usr/local/lib/python3.11/dist-packages/lightglue/lightglue.py:24: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)\n",
      "2025-12-07 21:59:24.903270: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1765144765.090993      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1765144765.145327      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from time import time, sleep\n",
    "import gc\n",
    "import numpy as np\n",
    "import h5py\n",
    "import dataclasses\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import kornia as K\n",
    "import kornia.feature as KF\n",
    "from lightglue import match_pair\n",
    "from lightglue import ALIKED, LightGlue\n",
    "from lightglue.utils import load_image, rbd\n",
    "from transformers import AutoImageProcessor, AutoModel\n",
    "import pycolmap\n",
    "sys.path.append('/kaggle/input/imc25-utils')\n",
    "from database import *\n",
    "from h5_to_db import *\n",
    "import metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd5c3da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T21:59:39.588035Z",
     "iopub.status.busy": "2025-12-07T21:59:39.587602Z",
     "iopub.status.idle": "2025-12-07T21:59:39.593868Z",
     "shell.execute_reply": "2025-12-07T21:59:39.593349Z"
    },
    "papermill": {
     "duration": 0.010891,
     "end_time": "2025-12-07T21:59:39.594867",
     "exception": false,
     "start_time": "2025-12-07T21:59:39.583976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# HYPERPARAMETER CONFIGURATION\n",
    "@dataclasses.dataclass\n",
    "class Config:\n",
    "    \"\"\"All tunable hyperparameters in one place\"\"\"\n",
    "    sim_threshold: float = 0.40\n",
    "    \n",
    "    min_pairs_per_image: int = 25\n",
    "    \n",
    "    exhaustive_threshold: int = 20\n",
    "    \n",
    "    num_features: int = 4000\n",
    "    \n",
    "    detection_threshold: float = 0.01\n",
    "    \n",
    "    resize_to: int = 1024\n",
    "    \n",
    "    min_matches: int = 20\n",
    "    \n",
    "    min_model_size: int = 3\n",
    "    \n",
    "    max_num_models: int = 30\n",
    "    \n",
    "    # Customize parameters for specific datasets\n",
    "    def get_for_dataset(self, dataset_name: str, num_images: int):\n",
    "        \"\"\"Apply adaptive parameters based on dataset characteristics\"\"\"\n",
    "        config = dataclasses.replace(self)\n",
    "        \n",
    "        # Adaptive based on dataset size\n",
    "        if num_images <= 30:\n",
    "            # Small scenes - can afford more features and higher resolution\n",
    "            config.num_features = 6000\n",
    "            config.resize_to = 2048\n",
    "            config.exhaustive_threshold = 30\n",
    "            config.detection_threshold = 0.005\n",
    "            \n",
    "        elif num_images >= 200:\n",
    "            # Large scenes - need more connectivity\n",
    "            config.sim_threshold = 0.35\n",
    "            config.min_pairs_per_image = 35\n",
    "            config.max_num_models = 50\n",
    "        \n",
    "        return config\n",
    "\n",
    "CONFIG = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcca017c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T21:59:39.601773Z",
     "iopub.status.busy": "2025-12-07T21:59:39.601589Z",
     "iopub.status.idle": "2025-12-07T21:59:39.617352Z",
     "shell.execute_reply": "2025-12-07T21:59:39.616635Z"
    },
    "papermill": {
     "duration": 0.020644,
     "end_time": "2025-12-07T21:59:39.618495",
     "exception": false,
     "start_time": "2025-12-07T21:59:39.597851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device=device(type='cuda')\n"
     ]
    }
   ],
   "source": [
    "# MAIN CODE\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'{device=}')\n",
    "\n",
    "def load_torch_image(fname, device=torch.device('cpu')):\n",
    "    img = K.io.load_image(fname, K.io.ImageLoadType.RGB32, device=device)[None, ...]\n",
    "    return img\n",
    "\n",
    "def get_global_desc(fnames, device=torch.device('cpu')):\n",
    "    processor = AutoImageProcessor.from_pretrained('/kaggle/input/dinov2/pytorch/base/1')\n",
    "    model = AutoModel.from_pretrained('/kaggle/input/dinov2/pytorch/base/1')\n",
    "    model = model.eval().to(device)\n",
    "    global_descs_dinov2 = []\n",
    "    \n",
    "    for i, img_fname_full in tqdm(enumerate(fnames), total=len(fnames)):\n",
    "        timg = load_torch_image(img_fname_full, device='cpu')\n",
    "        with torch.inference_mode():\n",
    "            inputs = processor(images=timg, return_tensors=\"pt\", do_rescale=False).to(device)\n",
    "            outputs = model(**inputs)\n",
    "            dino_mac = F.normalize(outputs.last_hidden_state[:, 1:].max(dim=1)[0], dim=1, p=2)\n",
    "        global_descs_dinov2.append(dino_mac.detach().cpu())\n",
    "    \n",
    "    return torch.cat(global_descs_dinov2, dim=0)\n",
    "\n",
    "def get_img_pairs_exhaustive(img_fnames):\n",
    "    index_pairs = []\n",
    "    for i in range(len(img_fnames)):\n",
    "        for j in range(i + 1, len(img_fnames)):\n",
    "            index_pairs.append((i, j))\n",
    "    return index_pairs\n",
    "\n",
    "def get_image_pairs_shortlist(fnames, sim_th, min_pairs, exhaustive_if_less, device):\n",
    "    num_imgs = len(fnames)\n",
    "    if num_imgs <= exhaustive_if_less:\n",
    "        return get_img_pairs_exhaustive(fnames)\n",
    "    \n",
    "    descs = get_global_desc(fnames, device=device)\n",
    "    dm = torch.cdist(descs, descs, p=2).detach().cpu().numpy()\n",
    "    \n",
    "    mask = dm <= sim_th\n",
    "    matching_list = []\n",
    "    ar = np.arange(num_imgs)\n",
    "    \n",
    "    for st_idx in range(num_imgs - 1):\n",
    "        mask_idx = mask[st_idx]\n",
    "        to_match = ar[mask_idx]\n",
    "        if len(to_match) < min_pairs:\n",
    "            to_match = np.argsort(dm[st_idx])[:min_pairs]\n",
    "        \n",
    "        for idx in to_match:\n",
    "            if st_idx == idx:\n",
    "                continue\n",
    "            if dm[st_idx, idx] < 1000:\n",
    "                matching_list.append(tuple(sorted((st_idx, idx.item()))))\n",
    "    \n",
    "    return sorted(list(set(matching_list)))\n",
    "\n",
    "def detect_aliked(img_fnames, feature_dir, num_features, detection_threshold, resize_to, device):\n",
    "    dtype = torch.float32\n",
    "    extractor = ALIKED(\n",
    "        max_num_keypoints=num_features,\n",
    "        detection_threshold=detection_threshold,\n",
    "        resize=resize_to\n",
    "    ).eval().to(device, dtype)\n",
    "    \n",
    "    os.makedirs(feature_dir, exist_ok=True)\n",
    "    \n",
    "    with h5py.File(f'{feature_dir}/keypoints.h5', mode='w') as f_kp, \\\n",
    "         h5py.File(f'{feature_dir}/descriptors.h5', mode='w') as f_desc:\n",
    "        \n",
    "        for img_path in tqdm(img_fnames):\n",
    "            key = img_path.split('/')[-1]\n",
    "            \n",
    "            with torch.inference_mode():\n",
    "                image = load_torch_image(img_path, device=device).to(dtype)\n",
    "                feats = extractor.extract(image)\n",
    "                \n",
    "                kpts = feats['keypoints'].reshape(-1, 2).detach().cpu().numpy()\n",
    "                descs = feats['descriptors'].reshape(len(kpts), -1).detach().cpu().numpy()\n",
    "                \n",
    "                f_kp[key] = kpts\n",
    "                f_desc[key] = descs\n",
    "\n",
    "def match_with_lightglue(img_fnames, index_pairs, feature_dir, min_matches, device, verbose=True):\n",
    "    lg_matcher = KF.LightGlueMatcher(\n",
    "        \"aliked\",\n",
    "        {\"width_confidence\": -1, \"depth_confidence\": -1, \"mp\": 'cuda' in str(device)}\n",
    "    ).eval().to(device)\n",
    "    \n",
    "    with h5py.File(f'{feature_dir}/keypoints.h5', mode='r') as f_kp, \\\n",
    "         h5py.File(f'{feature_dir}/descriptors.h5', mode='r') as f_desc, \\\n",
    "         h5py.File(f'{feature_dir}/matches.h5', mode='w') as f_match:\n",
    "        \n",
    "        for idx1, idx2 in tqdm(index_pairs):\n",
    "            key1 = img_fnames[idx1].split('/')[-1]\n",
    "            key2 = img_fnames[idx2].split('/')[-1]\n",
    "            \n",
    "            kp1 = torch.from_numpy(f_kp[key1][...]).to(device)\n",
    "            kp2 = torch.from_numpy(f_kp[key2][...]).to(device)\n",
    "            desc1 = torch.from_numpy(f_desc[key1][...]).to(device)\n",
    "            desc2 = torch.from_numpy(f_desc[key2][...]).to(device)\n",
    "            \n",
    "            with torch.inference_mode():\n",
    "                laf1 = KF.laf_from_center_scale_ori(kp1[None])\n",
    "                laf2 = KF.laf_from_center_scale_ori(kp2[None])\n",
    "                dists, idxs = lg_matcher(desc1, desc2, laf1, laf2)\n",
    "            \n",
    "            if len(idxs) == 0:\n",
    "                continue\n",
    "            \n",
    "            n_matches = len(idxs)\n",
    "            if verbose:\n",
    "                print(f'{key1}-{key2}: {n_matches} matches')\n",
    "            \n",
    "            if n_matches >= min_matches:\n",
    "                group = f_match.require_group(key1)\n",
    "                group.create_dataset(key2, data=idxs.detach().cpu().numpy().reshape(-1, 2))\n",
    "\n",
    "def import_into_colmap(img_dir, feature_dir, database_path):\n",
    "    db = COLMAPDatabase.connect(database_path)\n",
    "    db.create_tables()\n",
    "    fname_to_id = add_keypoints(db, feature_dir, img_dir, '', 'simple-pinhole', False)\n",
    "    add_matches(db, feature_dir, fname_to_id)\n",
    "    db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b0f87cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T21:59:39.625139Z",
     "iopub.status.busy": "2025-12-07T21:59:39.624916Z"
    },
    "papermill": {
     "duration": 69.067415,
     "end_time": "2025-12-07T22:00:48.688686",
     "exception": false,
     "start_time": "2025-12-07T21:59:39.621271",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset \"ETs\" -> num_images=22\n",
      "Dataset \"amy_gardens\" -> num_images=200\n",
      "Dataset \"fbk_vineyard\" -> num_images=163\n",
      "Dataset \"imc2023_haiper\" -> num_images=54\n",
      "Dataset \"imc2023_heritage\" -> num_images=209\n",
      "Dataset \"imc2023_theather_imc2024_church\" -> num_images=76\n",
      "Dataset \"imc2024_dioscuri_baalshamin\" -> num_images=138\n",
      "Dataset \"imc2024_lizard_pond\" -> num_images=214\n",
      "Dataset \"pt_brandenburg_british_buckingham\" -> num_images=225\n",
      "Dataset \"pt_piazzasanmarco_grandplace\" -> num_images=168\n",
      "Dataset \"pt_sacrecoeur_trevi_tajmahal\" -> num_images=225\n",
      "Dataset \"pt_stpeters_stpauls\" -> num_images=200\n",
      "Dataset \"stairs\" -> num_images=51\n",
      "\n",
      "Extracting on device cuda\n",
      "\n",
      "Default hyperparameters:\n",
      "  sim_threshold: 0.4\n",
      "  min_pairs_per_image: 25\n",
      "  num_features: 6000\n",
      "  detection_threshold: 0.01\n",
      "  resize_to: 1600\n",
      "  min_matches: 20\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Processing dataset \"ETs\": 22 images\n",
      "======================================================================\n",
      "Adaptive params: features=8000, resize=2048, sim_th=0.40, min_pairs=25\n",
      "✓ Shortlisting: 231 pairs in 0.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:02<00:00,  7.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Feature detection in 3.37s\n",
      "Loaded LightGlue model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 231/231 [01:02<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Feature matching in 62.27s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 74.80it/s]\n",
      " 73%|███████▎  | 111/153 [00:00<00:00, 3397.21it/s]\n",
      "I20251207 22:00:47.751047 135244795606592 misc.cc:44] \n",
      "==============================================================================\n",
      "Feature matching\n",
      "==============================================================================\n",
      "I20251207 22:00:47.751798 135244787213888 sift.cc:1432] Creating SIFT CPU feature matcher\n",
      "I20251207 22:00:47.751866 135244778821184 sift.cc:1432] Creating SIFT CPU feature matcher\n",
      "I20251207 22:00:47.752035 135244552332864 sift.cc:1432] Creating SIFT CPU feature matcher\n",
      "I20251207 22:00:47.752133 135244694943296 sift.cc:1432] Creating SIFT CPU feature matcher\n",
      "I20251207 22:00:47.752278 135244795606592 pairing.cc:168] Generating exhaustive image pairs...\n",
      "I20251207 22:00:47.752325 135244795606592 pairing.cc:201] Matching block [1/1, 1/1]\n",
      "terminate called after throwing an instance of 'std::domain_error'\n",
      "  what():  Camera model does not exist\n",
      "*** Aborted at 1765144847 (unix time) try \"date -d @1765144847\" if you are using GNU date ***\n",
      "terminate called recursively\n",
      "PC: @     0x7b03dc1d89fc pthread_kill\n",
      "*** SIGABRT (@0x13) received by PID 19 (TID 0x7b011affd640) from PID 19; stack trace: ***\n",
      "    @     0x7b03dc1dbee8 (/usr/lib/x86_64-linux-gnu/libc.so.6+0x99ee7)\n",
      "    @     0x7b02b698d388 (/usr/local/lib/python3.11/dist-packages/pycolmap/_core.cpython-311-x86_64-linux-gnu.so+0x69d387)\n",
      "    @     0x7b03dc184520 (/usr/lib/x86_64-linux-gnu/libc.so.6+0x4251f)\n",
      "    @     0x7b03dc1d89fc pthread_kill\n",
      "    @     0x7b03dc184476 raise\n",
      "    @     0x7b03dc16a7f3 abort\n",
      "    @     0x7b03db313b9e (/usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.30+0xa2b9d)\n",
      "    @     0x7b03db31f20c (/usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.30+0xae20b)\n",
      "    @     0x7b03db31f277 std::terminate()\n",
      "    @     0x7b03db31f4d8 __cxa_throw\n",
      "    @     0x7b02b6510404 (/usr/local/lib/python3.11/dist-packages/pycolmap/_core.cpython-311-x86_64-linux-gnu.so+0x220403)\n",
      "    @     0x7b02b6d0f5a5 colmap::EstimateCalibratedTwoViewGeometry(colmap::Camera const&, std::vector<Eigen::Matrix<double, 2, 1, 0, 2, 1>, std::allocator<Eigen::Matrix<double, 2, 1, 0, 2, 1> > > const&, colmap::Camera const&, std::vector<Eigen::Matrix<double, 2, 1, 0, 2, 1>, std:i\n",
      "    @     0x7b02b6d103c2 colmap::EstimateTwoViewGeometry(colmap::Camera const&, std::vector<Eigen::Matrix<double, 2, 1, 0, 2, 1>, std::allocator<Eigen::Matrix<double, 2, 1, 0, 2, 1> > > const&, colmap::Camera const&, std::vector<Eigen::Matrix<double, 2, 1, 0, 2, 1>, std::allocatori\n"
     ]
    }
   ],
   "source": [
    "@dataclasses.dataclass\n",
    "class Prediction:\n",
    "    image_id: str | None\n",
    "    dataset: str\n",
    "    filename: str\n",
    "    cluster_index: int | None = None\n",
    "    rotation: np.ndarray | None = None\n",
    "    translation: np.ndarray | None = None\n",
    "\n",
    "# Configuration\n",
    "is_train = False\n",
    "data_dir = '/kaggle/input/image-matching-challenge-2025'\n",
    "workdir = '/kaggle/working/result/'\n",
    "os.makedirs(workdir, exist_ok=True)\n",
    "\n",
    "sample_submission_csv = os.path.join(data_dir, 'train_labels.csv' if is_train else 'sample_submission.csv')\n",
    "\n",
    "# Load datasets\n",
    "samples = {}\n",
    "competition_data = pd.read_csv(sample_submission_csv)\n",
    "for _, row in competition_data.iterrows():\n",
    "    if row.dataset not in samples:\n",
    "        samples[row.dataset] = []\n",
    "    samples[row.dataset].append(\n",
    "        Prediction(\n",
    "            image_id=None if is_train else row.image_id,\n",
    "            dataset=row.dataset,\n",
    "            filename=row.image\n",
    "        )\n",
    "    )\n",
    "\n",
    "for dataset in samples:\n",
    "    print(f'Dataset \"{dataset}\" -> num_images={len(samples[dataset])}')\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "# Processing configuration\n",
    "max_images = None\n",
    "datasets_to_process = None\n",
    "if is_train:\n",
    "    datasets_to_process = ['amy_gardens', 'ETs', 'fbk_vineyard', 'stairs']\n",
    "\n",
    "# Processing\n",
    "timings = {\n",
    "    \"shortlisting\": [], \"feature_detection\": [], \"feature_matching\": [],\n",
    "    \"RANSAC\": [], \"Reconstruction\": [],\n",
    "}\n",
    "mapping_result_strs = []\n",
    "\n",
    "print(f\"\\nExtracting on device {device}\")\n",
    "print(f\"\\nDefault hyperparameters:\")\n",
    "print(f\"  sim_threshold: {CONFIG.sim_threshold}\")\n",
    "print(f\"  min_pairs_per_image: {CONFIG.min_pairs_per_image}\")\n",
    "print(f\"  num_features: {CONFIG.num_features}\")\n",
    "print(f\"  detection_threshold: {CONFIG.detection_threshold}\")\n",
    "print(f\"  resize_to: {CONFIG.resize_to}\")\n",
    "print(f\"  min_matches: {CONFIG.min_matches}\\n\")\n",
    "\n",
    "for dataset, predictions in samples.items():\n",
    "    if datasets_to_process and dataset not in datasets_to_process:\n",
    "        print(f'Skipping \"{dataset}\"')\n",
    "        continue\n",
    "    \n",
    "    images_dir = os.path.join(data_dir, 'train' if is_train else 'test', dataset)\n",
    "    images = [os.path.join(images_dir, p.filename) for p in predictions]\n",
    "    if max_images:\n",
    "        images = images[:max_images]\n",
    "    \n",
    "    num_images = len(images)\n",
    "    print(f'\\n{\"=\"*70}')\n",
    "    print(f'Processing dataset \"{dataset}\": {num_images} images')\n",
    "    print(f'{\"=\"*70}')\n",
    "    \n",
    "    # Get adaptive config for this dataset\n",
    "    cfg = CONFIG.get_for_dataset(dataset, num_images)\n",
    "    print(f\"Adaptive params: features={cfg.num_features}, resize={cfg.resize_to}, \"\n",
    "          f\"sim_th={cfg.sim_threshold:.2f}, min_pairs={cfg.min_pairs_per_image}\")\n",
    "    \n",
    "    filename_to_index = {p.filename: idx for idx, p in enumerate(predictions)}\n",
    "    feature_dir = os.path.join(workdir, 'featureout', dataset)\n",
    "    os.makedirs(feature_dir, exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        # Shortlisting\n",
    "        t = time()\n",
    "        index_pairs = get_image_pairs_shortlist(\n",
    "            images, cfg.sim_threshold, cfg.min_pairs_per_image,\n",
    "            cfg.exhaustive_threshold, device\n",
    "        )\n",
    "        timings['shortlisting'].append(time() - t)\n",
    "        print(f'✓ Shortlisting: {len(index_pairs)} pairs in {time() - t:.2f}s')\n",
    "        gc.collect()\n",
    "        \n",
    "        # Feature detection\n",
    "        t = time()\n",
    "        detect_aliked(images, feature_dir, cfg.num_features, \n",
    "                     cfg.detection_threshold, cfg.resize_to, device)\n",
    "        gc.collect()\n",
    "        timings['feature_detection'].append(time() - t)\n",
    "        print(f'✓ Feature detection in {time() - t:.2f}s')\n",
    "        \n",
    "        # Feature matching\n",
    "        t = time()\n",
    "        match_with_lightglue(images, index_pairs, feature_dir, \n",
    "                           cfg.min_matches, device, verbose=False)\n",
    "        timings['feature_matching'].append(time() - t)\n",
    "        print(f'✓ Feature matching in {time() - t:.2f}s')\n",
    "        \n",
    "        # Import to COLMAP\n",
    "        database_path = os.path.join(feature_dir, 'colmap.db')\n",
    "        if os.path.isfile(database_path):\n",
    "            os.remove(database_path)\n",
    "        gc.collect()\n",
    "        sleep(1)\n",
    "        import_into_colmap(images_dir, feature_dir, database_path)\n",
    "        output_path = f'{feature_dir}/colmap_rec_aliked'\n",
    "        \n",
    "        # RANSAC\n",
    "        t = time()\n",
    "        pycolmap.match_exhaustive(database_path)\n",
    "        timings['RANSAC'].append(time() - t)\n",
    "        print(f'✓ RANSAC in {time() - t:.2f}s')\n",
    "        \n",
    "        # Reconstruction\n",
    "        mapper_options = pycolmap.IncrementalPipelineOptions()\n",
    "        mapper_options.min_model_size = cfg.min_model_size\n",
    "        mapper_options.max_num_models = cfg.max_num_models\n",
    "        os.makedirs(output_path, exist_ok=True)\n",
    "        \n",
    "        t = time()\n",
    "        maps = pycolmap.incremental_mapping(\n",
    "            database_path=database_path,\n",
    "            image_path=images_dir,\n",
    "            output_path=output_path,\n",
    "            options=mapper_options\n",
    "        )\n",
    "        sleep(1)\n",
    "        timings['Reconstruction'].append(time() - t)\n",
    "        print(f'✓ Reconstruction in {time() - t:.2f}s')\n",
    "        clear_output(wait=False)\n",
    "        \n",
    "        # Store results\n",
    "        registered = 0\n",
    "        for map_index, cur_map in maps.items():\n",
    "            for index, image in cur_map.images.items():\n",
    "                prediction_index = filename_to_index[image.name]\n",
    "                predictions[prediction_index].cluster_index = map_index\n",
    "                predictions[prediction_index].rotation = deepcopy(image.cam_from_world.rotation.matrix())\n",
    "                predictions[prediction_index].translation = deepcopy(image.cam_from_world.translation)\n",
    "                registered += 1\n",
    "        \n",
    "        result = f'✓ \"{dataset}\": {registered}/{num_images} images, {len(maps)} clusters'\n",
    "        mapping_result_strs.append(result)\n",
    "        print(result)\n",
    "        gc.collect()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error: {e}\")\n",
    "        mapping_result_strs.append(f'✗ \"{dataset}\": Failed!')\n",
    "\n",
    "# Results\n",
    "print('\\nFINAL RESULTS:')\n",
    "for s in mapping_result_strs:\n",
    "    print(s)\n",
    "\n",
    "print('\\nTIMING SUMMARY:')\n",
    "for k, v in timings.items():\n",
    "    print(f'{k:20s}: {sum(v):7.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b673cba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T21:58:30.117643Z",
     "iopub.status.busy": "2025-12-07T21:58:30.117309Z",
     "iopub.status.idle": "2025-12-07T21:58:30.296509Z",
     "shell.execute_reply": "2025-12-07T21:58:30.295807Z",
     "shell.execute_reply.started": "2025-12-07T21:58:30.117616Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# submission\n",
    "array_to_str = lambda array: ';'.join([f\"{x:.09f}\" for x in array])\n",
    "none_to_str = lambda n: ';'.join(['nan'] * n)\n",
    "\n",
    "submission_file = '/kaggle/working/submission.csv'\n",
    "with open(submission_file, 'w') as f:\n",
    "    if is_train:\n",
    "        f.write('dataset,scene,image,rotation_matrix,translation_vector\\n')\n",
    "        for dataset in samples:\n",
    "            for prediction in samples[dataset]:\n",
    "                cluster = 'outliers' if prediction.cluster_index is None else f'cluster{prediction.cluster_index}'\n",
    "                rot = none_to_str(9) if prediction.rotation is None else array_to_str(prediction.rotation.flatten())\n",
    "                trans = none_to_str(3) if prediction.translation is None else array_to_str(prediction.translation)\n",
    "                f.write(f'{prediction.dataset},{cluster},{prediction.filename},{rot},{trans}\\n')\n",
    "    else:\n",
    "        f.write('image_id,dataset,scene,image,rotation_matrix,translation_vector\\n')\n",
    "        for dataset in samples:\n",
    "            for prediction in samples[dataset]:\n",
    "                cluster = 'outliers' if prediction.cluster_index is None else f'cluster{prediction.cluster_index}'\n",
    "                rot = none_to_str(9) if prediction.rotation is None else array_to_str(prediction.rotation.flatten())\n",
    "                trans = none_to_str(3) if prediction.translation is None else array_to_str(prediction.translation)\n",
    "                f.write(f'{prediction.image_id},{prediction.dataset},{cluster},{prediction.filename},{rot},{trans}\\n')\n",
    "\n",
    "print(f'\\nSubmission saved to: {submission_file}')\n",
    "!head {submission_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19157af",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11655853,
     "isSourceIdPinned": false,
     "sourceId": 91498,
     "sourceType": "competition"
    },
    {
     "datasetId": 7305232,
     "sourceId": 11660458,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6988459,
     "sourceId": 11924468,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 986,
     "modelInstanceId": 3326,
     "sourceId": 4534,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 22086,
     "modelInstanceId": 14611,
     "sourceId": 17555,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 21716,
     "modelInstanceId": 14317,
     "sourceId": 17191,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 108.055612,
   "end_time": "2025-12-07T22:00:48.704629",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-07T21:59:00.649017",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
