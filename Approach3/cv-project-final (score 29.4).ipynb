{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T19:11:21.403795Z",
     "iopub.status.busy": "2025-12-05T19:11:21.403526Z",
     "iopub.status.idle": "2025-12-05T19:15:10.386196Z",
     "shell.execute_reply": "2025-12-05T19:15:10.385391Z",
     "shell.execute_reply.started": "2025-12-05T19:11:21.403763Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install --no-index /kaggle/input/imc2025-packages-python-11-new/* --no-deps\n",
    "!mkdir -p /root/.cache/torch/hub/checkpoints\n",
    "!cp /kaggle/input/aliked/pytorch/aliked-n16/1/aliked-n16.pth /root/.cache/torch/hub/checkpoints/\n",
    "!cp /kaggle/input/lightglue/pytorch/aliked/1/aliked_lightglue.pth /root/.cache/torch/hub/checkpoints/\n",
    "!cp /kaggle/input/lightglue/pytorch/aliked/1/aliked_lightglue.pth /root/.cache/torch/hub/checkpoints/aliked_lightglue_v0-1_arxiv-pth\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from time import time, sleep\n",
    "import gc\n",
    "import numpy as np\n",
    "import h5py\n",
    "import dataclasses\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "from PIL import Image\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import kornia as K\n",
    "import kornia.feature as KF\n",
    "\n",
    "from lightglue import match_pair\n",
    "from lightglue import ALIKED, LightGlue\n",
    "from lightglue.utils import load_image, rbd\n",
    "from transformers import AutoImageProcessor, AutoModel\n",
    "\n",
    "# IMPORTANT Utilities: importing data into colmap and competition metric\n",
    "import pycolmap\n",
    "sys.path.append('/kaggle/input/imc25-utils')\n",
    "from database import *\n",
    "from h5_to_db import *\n",
    "import metric\n",
    "\n",
    "# Get device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'{device=}')\n",
    "\n",
    "def load_torch_image(fname, device=torch.device('cpu')):\n",
    "    \"\"\"Load image using Kornia 0.7.2 API\"\"\"\n",
    "    # Kornia 0.7.2 uses different enum values\n",
    "    img = K.io.load_image(fname, K.io.ImageLoadType.RGB32, device=device)[None, ...]\n",
    "    return img\n",
    "\n",
    "\n",
    "def get_global_desc(fnames, device=torch.device('cpu')):\n",
    "    \"\"\"Extract global descriptors using DINOv2\"\"\"\n",
    "    processor = AutoImageProcessor.from_pretrained('/kaggle/input/dinov2/pytorch/base/1')\n",
    "    model = AutoModel.from_pretrained('/kaggle/input/dinov2/pytorch/base/1')\n",
    "    model = model.eval()\n",
    "    model = model.to(device)\n",
    "    global_descs_dinov2 = []\n",
    "    \n",
    "    for i, img_fname_full in tqdm(enumerate(fnames), total=len(fnames)):\n",
    "        key = os.path.splitext(os.path.basename(img_fname_full))[0]\n",
    "        timg = load_torch_image(img_fname_full, device='cpu')\n",
    "        \n",
    "        with torch.inference_mode():\n",
    "            inputs = processor(images=timg, return_tensors=\"pt\", do_rescale=False).to(device)\n",
    "            outputs = model(**inputs)\n",
    "            dino_mac = F.normalize(outputs.last_hidden_state[:, 1:].max(dim=1)[0], dim=1, p=2)\n",
    "        \n",
    "        global_descs_dinov2.append(dino_mac.detach().cpu())\n",
    "    \n",
    "    global_descs_dinov2 = torch.cat(global_descs_dinov2, dim=0)\n",
    "    return global_descs_dinov2\n",
    "\n",
    "\n",
    "def get_img_pairs_exhaustive(img_fnames):\n",
    "    \"\"\"Generate all possible image pairs\"\"\"\n",
    "    index_pairs = []\n",
    "    for i in range(len(img_fnames)):\n",
    "        for j in range(i + 1, len(img_fnames)):\n",
    "            index_pairs.append((i, j))\n",
    "    return index_pairs\n",
    "\n",
    "\n",
    "def get_image_pairs_shortlist(fnames,\n",
    "                              sim_th=0.6,\n",
    "                              min_pairs=30,\n",
    "                              exhaustive_if_less=20,\n",
    "                              device=torch.device('cpu')):\n",
    "    \"\"\"Get image pairs based on global descriptor similarity\"\"\"\n",
    "    num_imgs = len(fnames)\n",
    "    if num_imgs <= exhaustive_if_less:\n",
    "        return get_img_pairs_exhaustive(fnames)\n",
    "    \n",
    "    descs = get_global_desc(fnames, device=device)\n",
    "    dm = torch.cdist(descs, descs, p=2).detach().cpu().numpy()\n",
    "    \n",
    "    mask = dm <= sim_th\n",
    "    matching_list = []\n",
    "    ar = np.arange(num_imgs)\n",
    "    \n",
    "    for st_idx in range(num_imgs - 1):\n",
    "        mask_idx = mask[st_idx]\n",
    "        to_match = ar[mask_idx]\n",
    "        \n",
    "        if len(to_match) < min_pairs:\n",
    "            to_match = np.argsort(dm[st_idx])[:min_pairs]\n",
    "        \n",
    "        for idx in to_match:\n",
    "            if st_idx == idx:\n",
    "                continue\n",
    "            if dm[st_idx, idx] < 1000:\n",
    "                matching_list.append(tuple(sorted((st_idx, idx.item()))))\n",
    "    \n",
    "    matching_list = sorted(list(set(matching_list)))\n",
    "    return matching_list\n",
    "\n",
    "\n",
    "def detect_aliked(img_fnames,\n",
    "                  feature_dir='.featureout',\n",
    "                  num_features=2048,\n",
    "                  resize_to=1024,\n",
    "                  device=torch.device('cpu')):\n",
    "    \"\"\"Detect features using ALIKED\"\"\"\n",
    "    dtype = torch.float32\n",
    "    extractor = ALIKED(max_num_keypoints=num_features, \n",
    "                      detection_threshold=0.01, \n",
    "                      resize=resize_to).eval().to(device, dtype)\n",
    "    \n",
    "    if not os.path.isdir(feature_dir):\n",
    "        os.makedirs(feature_dir)\n",
    "    \n",
    "    with h5py.File(f'{feature_dir}/keypoints.h5', mode='w') as f_kp, \\\n",
    "         h5py.File(f'{feature_dir}/descriptors.h5', mode='w') as f_desc:\n",
    "        \n",
    "        for img_path in tqdm(img_fnames):\n",
    "            img_fname = img_path.split('/')[-1]\n",
    "            key = img_fname\n",
    "            \n",
    "            with torch.inference_mode():\n",
    "                image0 = load_torch_image(img_path, device=device).to(dtype)\n",
    "                feats0 = extractor.extract(image0)\n",
    "                \n",
    "                kpts = feats0['keypoints'].reshape(-1, 2).detach().cpu().numpy()\n",
    "                descs = feats0['descriptors'].reshape(len(kpts), -1).detach().cpu().numpy()\n",
    "                \n",
    "                f_kp[key] = kpts\n",
    "                f_desc[key] = descs\n",
    "\n",
    "\n",
    "def match_with_lightglue(img_fnames,\n",
    "                         index_pairs,\n",
    "                         feature_dir='.featureout',\n",
    "                         device=torch.device('cpu'),\n",
    "                         min_matches=25,\n",
    "                         verbose=True):\n",
    "    \"\"\"Match features using LightGlue with Kornia 0.7.2 API\"\"\"\n",
    "    # Initialize LightGlue matcher with updated API\n",
    "    lg_matcher = KF.LightGlueMatcher(\n",
    "        \"aliked\", \n",
    "        {\n",
    "            \"width_confidence\": -1,\n",
    "            \"depth_confidence\": -1,\n",
    "            \"mp\": True if 'cuda' in str(device) else False\n",
    "        }\n",
    "    ).eval().to(device)\n",
    "    \n",
    "    with h5py.File(f'{feature_dir}/keypoints.h5', mode='r') as f_kp, \\\n",
    "         h5py.File(f'{feature_dir}/descriptors.h5', mode='r') as f_desc, \\\n",
    "         h5py.File(f'{feature_dir}/matches.h5', mode='w') as f_match:\n",
    "        \n",
    "        for pair_idx in tqdm(index_pairs):\n",
    "            idx1, idx2 = pair_idx\n",
    "            fname1, fname2 = img_fnames[idx1], img_fnames[idx2]\n",
    "            key1, key2 = fname1.split('/')[-1], fname2.split('/')[-1]\n",
    "            \n",
    "            kp1 = torch.from_numpy(f_kp[key1][...]).to(device)\n",
    "            kp2 = torch.from_numpy(f_kp[key2][...]).to(device)\n",
    "            desc1 = torch.from_numpy(f_desc[key1][...]).to(device)\n",
    "            desc2 = torch.from_numpy(f_desc[key2][...]).to(device)\n",
    "            \n",
    "            with torch.inference_mode():\n",
    "                # Create LAFs from keypoints for Kornia 0.7.2\n",
    "                laf1 = KF.laf_from_center_scale_ori(kp1[None])\n",
    "                laf2 = KF.laf_from_center_scale_ori(kp2[None])\n",
    "                \n",
    "                dists, idxs = lg_matcher(desc1, desc2, laf1, laf2)\n",
    "            \n",
    "            if len(idxs) == 0:\n",
    "                continue\n",
    "            \n",
    "            n_matches = len(idxs)\n",
    "            if verbose:\n",
    "                print(f'{key1}-{key2}: {n_matches} matches')\n",
    "            \n",
    "            group = f_match.require_group(key1)\n",
    "            if n_matches >= min_matches:\n",
    "                group.create_dataset(key2, data=idxs.detach().cpu().numpy().reshape(-1, 2))\n",
    "\n",
    "\n",
    "def import_into_colmap(img_dir, feature_dir='.featureout', database_path='colmap.db'):\n",
    "    \"\"\"Import features and matches into COLMAP database\"\"\"\n",
    "    db = COLMAPDatabase.connect(database_path)\n",
    "    db.create_tables()\n",
    "    single_camera = False\n",
    "    fname_to_id = add_keypoints(db, feature_dir, img_dir, '', 'simple-pinhole', single_camera)\n",
    "    add_matches(db, feature_dir, fname_to_id)\n",
    "    db.commit()\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class Prediction:\n",
    "    image_id: str | None\n",
    "    dataset: str\n",
    "    filename: str\n",
    "    cluster_index: int | None = None\n",
    "    rotation: np.ndarray | None = None\n",
    "    translation: np.ndarray | None = None\n",
    "\n",
    "\n",
    "# Configuration\n",
    "is_train = False\n",
    "data_dir = '/kaggle/input/image-matching-challenge-2025'\n",
    "workdir = '/kaggle/working/result/'\n",
    "os.makedirs(workdir, exist_ok=True)\n",
    "\n",
    "if is_train:\n",
    "    sample_submission_csv = os.path.join(data_dir, 'train_labels.csv')\n",
    "else:\n",
    "    sample_submission_csv = os.path.join(data_dir, 'sample_submission.csv')\n",
    "\n",
    "# Load dataset information\n",
    "samples = {}\n",
    "competition_data = pd.read_csv(sample_submission_csv)\n",
    "for _, row in competition_data.iterrows():\n",
    "    if row.dataset not in samples:\n",
    "        samples[row.dataset] = []\n",
    "    samples[row.dataset].append(\n",
    "        Prediction(\n",
    "            image_id=None if is_train else row.image_id,\n",
    "            dataset=row.dataset,\n",
    "            filename=row.image\n",
    "        )\n",
    "    )\n",
    "\n",
    "for dataset in samples:\n",
    "    print(f'Dataset \"{dataset}\" -> num_images={len(samples[dataset])}')\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "# Configuration for processing\n",
    "max_images = None\n",
    "datasets_to_process = None\n",
    "\n",
    "if is_train:\n",
    "    datasets_to_process = [\n",
    "        'ETs',\n",
    "        'stairs',\n",
    "    ]\n",
    "\n",
    "# Processing\n",
    "timings = {\n",
    "    \"shortlisting\": [],\n",
    "    \"feature_detection\": [],\n",
    "    \"feature_matching\": [],\n",
    "    \"RANSAC\": [],\n",
    "    \"Reconstruction\": [],\n",
    "}\n",
    "mapping_result_strs = []\n",
    "\n",
    "print(f\"Extracting on device {device}\")\n",
    "\n",
    "for dataset, predictions in samples.items():\n",
    "    if datasets_to_process and dataset not in datasets_to_process:\n",
    "        print(f'Skipping \"{dataset}\"')\n",
    "        continue\n",
    "    \n",
    "    images_dir = os.path.join(data_dir, 'train' if is_train else 'test', dataset)\n",
    "    images = [os.path.join(images_dir, p.filename) for p in predictions]\n",
    "    if max_images is not None:\n",
    "        images = images[:max_images]\n",
    "\n",
    "    print(f'\\nProcessing dataset \"{dataset}\": {len(images)} images')\n",
    "\n",
    "    filename_to_index = {p.filename: idx for idx, p in enumerate(predictions)}\n",
    "\n",
    "    feature_dir = os.path.join(workdir, 'featureout', dataset)\n",
    "    os.makedirs(feature_dir, exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        # Shortlisting\n",
    "        t = time()\n",
    "        index_pairs = get_image_pairs_shortlist(\n",
    "            images,\n",
    "            sim_th=0.3,\n",
    "            min_pairs=20,\n",
    "            exhaustive_if_less=20,\n",
    "            device=device\n",
    "        )\n",
    "        timings['shortlisting'].append(time() - t)\n",
    "        print(f'Shortlisting. Number of pairs to match: {len(index_pairs)}. Done in {time() - t:.4f} sec')\n",
    "        gc.collect()\n",
    "    \n",
    "        # Feature detection\n",
    "        t = time()\n",
    "        detect_aliked(images, feature_dir, 5000, device=device)\n",
    "        gc.collect()\n",
    "        timings['feature_detection'].append(time() - t)\n",
    "        print(f'Features detected in {time() - t:.4f} sec')\n",
    "        \n",
    "        # Feature matching\n",
    "        t = time()\n",
    "        match_with_lightglue(images, index_pairs, feature_dir=feature_dir, \n",
    "                           device=device, min_matches=20, verbose=False)\n",
    "        timings['feature_matching'].append(time() - t)\n",
    "        print(f'Features matched in {time() - t:.4f} sec')\n",
    "\n",
    "        # Import to COLMAP\n",
    "        database_path = os.path.join(feature_dir, 'colmap.db')\n",
    "        if os.path.isfile(database_path):\n",
    "            os.remove(database_path)\n",
    "        gc.collect()\n",
    "        sleep(1)\n",
    "        import_into_colmap(images_dir, feature_dir=feature_dir, database_path=database_path)\n",
    "        output_path = f'{feature_dir}/colmap_rec_aliked'\n",
    "        \n",
    "        # RANSAC\n",
    "        t = time()\n",
    "        pycolmap.match_exhaustive(database_path)\n",
    "        timings['RANSAC'].append(time() - t)\n",
    "        print(f'Ran RANSAC in {time() - t:.4f} sec')\n",
    "        \n",
    "        # Reconstruction\n",
    "        mapper_options = pycolmap.IncrementalPipelineOptions()\n",
    "        mapper_options.min_model_size = 3\n",
    "        mapper_options.max_num_models = 25\n",
    "        os.makedirs(output_path, exist_ok=True)\n",
    "        \n",
    "        t = time()\n",
    "        maps = pycolmap.incremental_mapping(\n",
    "            database_path=database_path,\n",
    "            image_path=images_dir,\n",
    "            output_path=output_path,\n",
    "            options=mapper_options\n",
    "        )\n",
    "        sleep(1)\n",
    "        timings['Reconstruction'].append(time() - t)\n",
    "        print(f'Reconstruction done in {time() - t:.4f} sec')\n",
    "        print(maps)\n",
    "\n",
    "        clear_output(wait=False)\n",
    "    \n",
    "        # Store results\n",
    "        registered = 0\n",
    "        for map_index, cur_map in maps.items():\n",
    "            for index, image in cur_map.images.items():\n",
    "                prediction_index = filename_to_index[image.name]\n",
    "                predictions[prediction_index].cluster_index = map_index\n",
    "                predictions[prediction_index].rotation = deepcopy(image.cam_from_world.rotation.matrix())\n",
    "                predictions[prediction_index].translation = deepcopy(image.cam_from_world.translation)\n",
    "                registered += 1\n",
    "        \n",
    "        mapping_result_str = f'Dataset \"{dataset}\" -> Registered {registered} / {len(images)} images with {len(maps)} clusters'\n",
    "        mapping_result_strs.append(mapping_result_str)\n",
    "        print(mapping_result_str)\n",
    "        gc.collect()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {dataset}: {e}\")\n",
    "        mapping_result_str = f'Dataset \"{dataset}\" -> Failed!'\n",
    "        mapping_result_strs.append(mapping_result_str)\n",
    "        print(mapping_result_str)\n",
    "\n",
    "# Print results\n",
    "print('\\nResults')\n",
    "for s in mapping_result_strs:\n",
    "    print(s)\n",
    "\n",
    "print('\\nTimings')\n",
    "for k, v in timings.items():\n",
    "    print(f'{k} -> total={sum(v):.02f} sec.')\n",
    "\n",
    "# Create submission file\n",
    "array_to_str = lambda array: ';'.join([f\"{x:.09f}\" for x in array])\n",
    "none_to_str = lambda n: ';'.join(['nan'] * n)\n",
    "\n",
    "submission_file = '/kaggle/working/submission.csv'\n",
    "with open(submission_file, 'w') as f:\n",
    "    if is_train:\n",
    "        f.write('dataset,scene,image,rotation_matrix,translation_vector\\n')\n",
    "        for dataset in samples:\n",
    "            for prediction in samples[dataset]:\n",
    "                cluster_name = 'outliers' if prediction.cluster_index is None else f'cluster{prediction.cluster_index}'\n",
    "                rotation = none_to_str(9) if prediction.rotation is None else array_to_str(prediction.rotation.flatten())\n",
    "                translation = none_to_str(3) if prediction.translation is None else array_to_str(prediction.translation)\n",
    "                f.write(f'{prediction.dataset},{cluster_name},{prediction.filename},{rotation},{translation}\\n')\n",
    "    else:\n",
    "        f.write('image_id,dataset,scene,image,rotation_matrix,translation_vector\\n')\n",
    "        for dataset in samples:\n",
    "            for prediction in samples[dataset]:\n",
    "                cluster_name = 'outliers' if prediction.cluster_index is None else f'cluster{prediction.cluster_index}'\n",
    "                rotation = none_to_str(9) if prediction.rotation is None else array_to_str(prediction.rotation.flatten())\n",
    "                translation = none_to_str(3) if prediction.translation is None else array_to_str(prediction.translation)\n",
    "                f.write(f'{prediction.image_id},{prediction.dataset},{cluster_name},{prediction.filename},{rotation},{translation}\\n')\n",
    "\n",
    "!head {submission_file}"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11655853,
     "sourceId": 91498,
     "sourceType": "competition"
    },
    {
     "datasetId": 7305232,
     "sourceId": 11660458,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6988459,
     "sourceId": 11924468,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 986,
     "modelInstanceId": 3326,
     "sourceId": 4534,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 21716,
     "modelInstanceId": 14317,
     "sourceId": 17191,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 22086,
     "modelInstanceId": 14611,
     "sourceId": 17555,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
